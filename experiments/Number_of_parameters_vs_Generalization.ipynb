{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)  # or any {DEBUG, INFO, WARN, ERROR, FATAL}\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets('data/MNIST/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of:\n",
      "- Training-set:\t\t55000\n",
      "- Test-set:\t\t10000\n",
      "- Validation-set:\t5000\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(len(data.train.labels)))\n",
    "print(\"- Test-set:\\t\\t{}\".format(len(data.test.labels)))\n",
    "print(\"- Validation-set:\\t{}\".format(len(data.validation.labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.test.cls = np.argmax(data.test.labels, axis=1)\n",
    "# We know that MNIST images are 28 pixels in each dimension.\n",
    "img_size = 28\n",
    "\n",
    "# Images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = img_size * img_size\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "# Number of colour channels for the images: 1 channel for gray-scale.\n",
    "num_channels = 1\n",
    "\n",
    "# Number of classes, one class for each of 10 digits.\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prameter_num():\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        # shape is an array of tf.Dimension\n",
    "        #print(variable)\n",
    "        shape = variable.get_shape()\n",
    "        #print(shape)\n",
    "        #print(len(shape))\n",
    "        variable_parameters = 1\n",
    "        for dim in shape:\n",
    "            #print(dim)\n",
    "            variable_parameters *= dim.value\n",
    "        #print(variable_parameters)\n",
    "        total_parameters += variable_parameters\n",
    "    return total_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"max_pooling2d/MaxPool:0\", shape=(?, 14, 14, 6), dtype=float32)\n",
      "Tensor(\"flatten/Reshape:0\", shape=(?, 1176), dtype=float32)\n",
      "Tensor(\"layer_fc_out/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "Total Parameters number = 152102\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\n",
    "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)\n",
    "\n",
    "# layer_conv1\n",
    "net = tf.layers.conv2d(inputs=x_image, name='layer_conv1', padding='same',\n",
    "                       filters=6, kernel_size=5, activation=tf.nn.relu)\n",
    "net = tf.layers.max_pooling2d(inputs=net, pool_size=2, strides=2)\n",
    "\n",
    "print(net)\n",
    "\n",
    "net = tf.layers.flatten(net)\n",
    "print(net)\n",
    "\n",
    "net = tf.layers.dense(inputs=net, name='layer_fc1',\n",
    "                      units=128, activation=tf.nn.relu)\n",
    "logits = tf.layers.dense(inputs=net, name='layer_fc_out',\n",
    "                      units=num_classes, activation=None)\n",
    "print(logits)\n",
    "\n",
    "y_pred = tf.nn.softmax(logits=logits)\n",
    "y_pred_cls = tf.argmax(y_pred, dimension=1)\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=logits)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "opt = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "optimizer = opt.minimize(loss)\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "trainable_var_list = tf.trainable_variables()\n",
    "\n",
    "par_num1 = prameter_num()\n",
    "\n",
    "print(\"Total Parameters number = %s\"  %par_num1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Testing Accuracy: 0.9726\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = 64\n",
    "n_batch = data.train.num_examples // train_batch_size\n",
    "\n",
    "loss_list1 = []\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for epoch in range(1):\n",
    "    for batch in range(n_batch):\n",
    "        batch_xs, batch_ys = data.train.next_batch(train_batch_size)\n",
    "        sess.run(optimizer, feed_dict={x:batch_xs, y_true:batch_ys})\n",
    "    loss1 = sess.run(loss, feed_dict={x:data.test.images,y_true:data.test.labels})\n",
    "    acc1 = sess.run(accuracy, feed_dict={x:data.test.images,y_true:data.test.labels})\n",
    "    lTrain1 = sess.run(loss, feed_dict={x:batch_xs, y_true:batch_ys})\n",
    "    aTrain1 = sess.run(accuracy, feed_dict={x:batch_xs, y_true:batch_ys})\n",
    "    print(\"Epoch \" + str(epoch) + \" Testing Accuracy: \" + str(acc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"max_pooling2d/MaxPool:0\", shape=(?, 4, 4, 2), dtype=float32)\n",
      "Tensor(\"flatten/Reshape:0\", shape=(?, 32), dtype=float32)\n",
      "Tensor(\"layer_fc_out/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "Total Parameters number = 750\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\n",
    "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)\n",
    "\n",
    "# layer_conv1\n",
    "net = tf.layers.conv2d(inputs=x_image, name='layer_conv1', padding='same',\n",
    "                       filters=2, kernel_size=5, activation=tf.nn.relu)\n",
    "net = tf.layers.max_pooling2d(inputs=net, pool_size=2, strides=8)\n",
    "\n",
    "print(net)\n",
    "\n",
    "net = tf.layers.flatten(net)\n",
    "print(net)\n",
    "\n",
    "net = tf.layers.dense(inputs=net, name='layer_fc1',\n",
    "                      units=16, activation=tf.nn.relu)\n",
    "logits = tf.layers.dense(inputs=net, name='layer_fc_out',\n",
    "                      units=num_classes, activation=None)\n",
    "print(logits)\n",
    "\n",
    "y_pred = tf.nn.softmax(logits=logits)\n",
    "y_pred_cls = tf.argmax(y_pred, dimension=1)\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=logits)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "opt = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "optimizer = opt.minimize(loss)\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "trainable_var_list = tf.trainable_variables()\n",
    "\n",
    "par_num2 = prameter_num()\n",
    "\n",
    "print(\"Total Parameters number = %s\"  %par_num2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Testing Accuracy: 0.8314\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = 64\n",
    "n_batch = data.train.num_examples // train_batch_size\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for epoch in range(1):\n",
    "    for batch in range(n_batch):\n",
    "        batch_xs, batch_ys = data.train.next_batch(train_batch_size)\n",
    "        sess.run(optimizer, feed_dict={x:batch_xs, y_true:batch_ys})\n",
    "    loss2 = sess.run(loss, feed_dict={x:data.test.images,y_true:data.test.labels})\n",
    "    acc2 = sess.run(accuracy, feed_dict={x:data.test.images,y_true:data.test.labels})\n",
    "    lTrain2 = sess.run(loss, feed_dict={x:batch_xs, y_true:batch_ys})\n",
    "    aTrain2 = sess.run(accuracy, feed_dict={x:batch_xs, y_true:batch_ys})\n",
    "    print(\"Epoch \" + str(epoch) + \" Testing Accuracy: \" + str(acc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"max_pooling2d/MaxPool:0\", shape=(?, 4, 4, 1), dtype=float32)\n",
      "Tensor(\"flatten/Reshape:0\", shape=(?, 16), dtype=float32)\n",
      "Tensor(\"layer_fc_out/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "Total Parameters number = 236\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\n",
    "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)\n",
    "\n",
    "# layer_conv1\n",
    "net = tf.layers.conv2d(inputs=x_image, name='layer_conv1', padding='same',\n",
    "                       filters=1, kernel_size=3, activation=tf.nn.relu)\n",
    "net = tf.layers.max_pooling2d(inputs=net, pool_size=4, strides=8)\n",
    "\n",
    "print(net)\n",
    "\n",
    "net = tf.layers.flatten(net)\n",
    "print(net)\n",
    "\n",
    "net = tf.layers.dense(inputs=net, name='layer_fc1',\n",
    "                      units=8, activation=tf.nn.relu)\n",
    "logits = tf.layers.dense(inputs=net, name='layer_fc_out',\n",
    "                      units=num_classes, activation=None)\n",
    "print(logits)\n",
    "\n",
    "y_pred = tf.nn.softmax(logits=logits)\n",
    "y_pred_cls = tf.argmax(y_pred, dimension=1)\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=logits)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "opt = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "optimizer = opt.minimize(loss)\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "trainable_var_list = tf.trainable_variables()\n",
    "\n",
    "par_num3 = prameter_num()\n",
    "\n",
    "print(\"Total Parameters number = %s\"  %par_num3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Testing Accuracy: 0.6617\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = 64\n",
    "n_batch = data.train.num_examples // train_batch_size\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for epoch in range(1):\n",
    "    for batch in range(n_batch):\n",
    "        batch_xs, batch_ys = data.train.next_batch(train_batch_size)\n",
    "        sess.run(optimizer, feed_dict={x:batch_xs, y_true:batch_ys})\n",
    "    loss3 = sess.run(loss, feed_dict={x:data.test.images,y_true:data.test.labels})\n",
    "    acc3 = sess.run(accuracy, feed_dict={x:data.test.images,y_true:data.test.labels})\n",
    "    lTrain3 = sess.run(loss, feed_dict={x:batch_xs, y_true:batch_ys})\n",
    "    aTrain3 = sess.run(accuracy, feed_dict={x:batch_xs, y_true:batch_ys})\n",
    "    print(\"Epoch \" + str(epoch) + \" Testing Accuracy: \" + str(acc3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"max_pooling2d/MaxPool:0\", shape=(?, 7, 7, 2), dtype=float32)\n",
      "Tensor(\"flatten/Reshape:0\", shape=(?, 98), dtype=float32)\n",
      "Tensor(\"layer_fc_out/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "Total Parameters number = 14014\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\n",
    "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)\n",
    "\n",
    "# layer_conv1\n",
    "net = tf.layers.conv2d(inputs=x_image, name='layer_conv1', padding='same',\n",
    "                       filters=2, kernel_size=5, activation=tf.nn.relu)\n",
    "net = tf.layers.max_pooling2d(inputs=net, pool_size=4, strides=4)\n",
    "\n",
    "print(net)\n",
    "\n",
    "net = tf.layers.flatten(net)\n",
    "print(net)\n",
    "\n",
    "net = tf.layers.dense(inputs=net, name='layer_fc1',\n",
    "                      units=128, activation=tf.nn.relu)\n",
    "logits = tf.layers.dense(inputs=net, name='layer_fc_out',\n",
    "                      units=num_classes, activation=None)\n",
    "print(logits)\n",
    "\n",
    "y_pred = tf.nn.softmax(logits=logits)\n",
    "y_pred_cls = tf.argmax(y_pred, dimension=1)\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=logits)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "opt = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "optimizer = opt.minimize(loss)\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "trainable_var_list = tf.trainable_variables()\n",
    "\n",
    "par_num4 = prameter_num()\n",
    "\n",
    "print(\"Total Parameters number = %s\"  %par_num4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Testing Accuracy: 0.9526\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = 64\n",
    "n_batch = data.train.num_examples // train_batch_size\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for epoch in range(1):\n",
    "    for batch in range(n_batch):\n",
    "        batch_xs, batch_ys = data.train.next_batch(train_batch_size)\n",
    "        sess.run(optimizer, feed_dict={x:batch_xs, y_true:batch_ys})\n",
    "    loss4 = sess.run(loss, feed_dict={x:data.test.images,y_true:data.test.labels})\n",
    "    acc4 = sess.run(accuracy, feed_dict={x:data.test.images,y_true:data.test.labels})\n",
    "    lTrain4 = sess.run(loss, feed_dict={x:batch_xs, y_true:batch_ys})\n",
    "    aTrain4 = sess.run(accuracy, feed_dict={x:batch_xs, y_true:batch_ys})\n",
    "    print(\"Epoch \" + str(epoch) + \" Testing Accuracy: \" + str(acc4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"max_pooling2d/MaxPool:0\", shape=(?, 3, 3, 2), dtype=float32)\n",
      "Tensor(\"flatten/Reshape:0\", shape=(?, 18), dtype=float32)\n",
      "Tensor(\"layer_fc_out/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "Total Parameters number = 494\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\n",
    "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)\n",
    "\n",
    "# layer_conv1\n",
    "net = tf.layers.conv2d(inputs=x_image, name='layer_conv1', padding='same',\n",
    "                       filters=2, kernel_size=3, activation=tf.nn.relu)\n",
    "net = tf.layers.max_pooling2d(inputs=net, pool_size=8, strides=8)\n",
    "\n",
    "print(net)\n",
    "\n",
    "net = tf.layers.flatten(net)\n",
    "print(net)\n",
    "\n",
    "net = tf.layers.dense(inputs=net, name='layer_fc1',\n",
    "                      units=16, activation=tf.nn.relu)\n",
    "logits = tf.layers.dense(inputs=net, name='layer_fc_out',\n",
    "                      units=num_classes, activation=None)\n",
    "print(logits)\n",
    "\n",
    "y_pred = tf.nn.softmax(logits=logits)\n",
    "y_pred_cls = tf.argmax(y_pred, dimension=1)\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=logits)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "opt = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "optimizer = opt.minimize(loss)\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "trainable_var_list = tf.trainable_variables()\n",
    "\n",
    "par_num5 = prameter_num()\n",
    "\n",
    "print(\"Total Parameters number = %s\"  %par_num5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Testing Accuracy: 0.8124\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = 64\n",
    "n_batch = data.train.num_examples // train_batch_size\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for epoch in range(1):\n",
    "    for batch in range(n_batch):\n",
    "        batch_xs, batch_ys = data.train.next_batch(train_batch_size)\n",
    "        sess.run(optimizer, feed_dict={x:batch_xs, y_true:batch_ys})\n",
    "    loss5 = sess.run(loss, feed_dict={x:data.test.images,y_true:data.test.labels})\n",
    "    acc5 = sess.run(accuracy, feed_dict={x:data.test.images,y_true:data.test.labels})\n",
    "    lTrain5 = sess.run(loss, feed_dict={x:batch_xs, y_true:batch_ys})\n",
    "    aTrain5 = sess.run(accuracy, feed_dict={x:batch_xs, y_true:batch_ys})\n",
    "    print(\"Epoch \" + str(epoch) + \" Testing Accuracy: \" + str(acc5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"max_pooling2d/MaxPool:0\", shape=(?, 14, 14, 8), dtype=float32)\n",
      "Tensor(\"flatten/Reshape:0\", shape=(?, 1568), dtype=float32)\n",
      "Tensor(\"layer_fc_out/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "Total Parameters number = 101274\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\n",
    "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)\n",
    "\n",
    "# layer_conv1\n",
    "net = tf.layers.conv2d(inputs=x_image, name='layer_conv1', padding='same',\n",
    "                       filters=8, kernel_size=5, activation=tf.nn.relu)\n",
    "net = tf.layers.max_pooling2d(inputs=net, pool_size=2, strides=2)\n",
    "\n",
    "print(net)\n",
    "\n",
    "net = tf.layers.flatten(net)\n",
    "print(net)\n",
    "\n",
    "net = tf.layers.dense(inputs=net, name='layer_fc1',\n",
    "                      units=64, activation=tf.nn.relu)\n",
    "logits = tf.layers.dense(inputs=net, name='layer_fc_out',\n",
    "                      units=num_classes, activation=None)\n",
    "print(logits)\n",
    "\n",
    "y_pred = tf.nn.softmax(logits=logits)\n",
    "y_pred_cls = tf.argmax(y_pred, dimension=1)\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=logits)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "opt = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "optimizer = opt.minimize(loss)\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "trainable_var_list = tf.trainable_variables()\n",
    "\n",
    "par_num6 = prameter_num()\n",
    "\n",
    "print(\"Total Parameters number = %s\"  %par_num6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Testing Accuracy: 0.9807\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = 64\n",
    "n_batch = data.train.num_examples // train_batch_size\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for epoch in range(1):\n",
    "    for batch in range(n_batch):\n",
    "        batch_xs, batch_ys = data.train.next_batch(train_batch_size)\n",
    "        sess.run(optimizer, feed_dict={x:batch_xs, y_true:batch_ys})\n",
    "    loss6 = sess.run(loss, feed_dict={x:data.test.images,y_true:data.test.labels})\n",
    "    acc6 = sess.run(accuracy, feed_dict={x:data.test.images,y_true:data.test.labels})\n",
    "    lTrain6 = sess.run(loss, feed_dict={x:batch_xs, y_true:batch_ys})\n",
    "    aTrain6 = sess.run(accuracy, feed_dict={x:batch_xs, y_true:batch_ys})\n",
    "    print(\"Epoch \" + str(epoch) + \" Testing Accuracy: \" + str(acc6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"max_pooling2d/MaxPool:0\", shape=(?, 14, 14, 26), dtype=float32)\n",
      "Tensor(\"max_pooling2d_1/MaxPool:0\", shape=(?, 7, 7, 16), dtype=float32)\n",
      "Tensor(\"flatten/Reshape:0\", shape=(?, 784), dtype=float32)\n",
      "Tensor(\"layer_fc_out/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "Total Parameters number = 61982\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\n",
    "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)\n",
    "\n",
    "# layer_conv1\n",
    "net = tf.layers.conv2d(inputs=x_image, name='layer_conv1', padding='same',\n",
    "                       filters=26, kernel_size=5, activation=tf.nn.relu)\n",
    "net = tf.layers.max_pooling2d(inputs=net, pool_size=2, strides=2)\n",
    "\n",
    "print(net)\n",
    "\n",
    "# layer_conv2\n",
    "net = tf.layers.conv2d(inputs=net, name='layer_conv2', padding='same',\n",
    "                       filters=16, kernel_size=5, activation=tf.nn.relu)\n",
    "net = tf.layers.max_pooling2d(inputs=net, pool_size=2, strides=2)\n",
    "print(net)\n",
    "\n",
    "net = tf.layers.flatten(net)\n",
    "print(net)\n",
    "\n",
    "net = tf.layers.dense(inputs=net, name='layer_fc1',\n",
    "                      units=64, activation=tf.nn.relu)\n",
    "logits = tf.layers.dense(inputs=net, name='layer_fc_out',\n",
    "                      units=num_classes, activation=None)\n",
    "print(logits)\n",
    "\n",
    "y_pred = tf.nn.softmax(logits=logits)\n",
    "y_pred_cls = tf.argmax(y_pred, dimension=1)\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=logits)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "opt = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "optimizer = opt.minimize(loss)\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "trainable_var_list = tf.trainable_variables()\n",
    "\n",
    "par_num7 = prameter_num()\n",
    "\n",
    "print(\"Total Parameters number = %s\"  %par_num7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Testing Accuracy: 0.9795\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = 64\n",
    "n_batch = data.train.num_examples // train_batch_size\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for epoch in range(1):\n",
    "    for batch in range(n_batch):\n",
    "        batch_xs, batch_ys = data.train.next_batch(train_batch_size)\n",
    "        sess.run(optimizer, feed_dict={x:batch_xs, y_true:batch_ys})\n",
    "    loss7 = sess.run(loss, feed_dict={x:data.test.images,y_true:data.test.labels})\n",
    "    acc7 = sess.run(accuracy, feed_dict={x:data.test.images,y_true:data.test.labels})\n",
    "    lTrain7 = sess.run(loss, feed_dict={x:batch_xs, y_true:batch_ys})\n",
    "    aTrain7 = sess.run(accuracy, feed_dict={x:batch_xs, y_true:batch_ys})\n",
    "    print(\"Epoch \" + str(epoch) + \" Testing Accuracy: \" + str(acc7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"max_pooling2d/MaxPool:0\", shape=(?, 13, 13, 4), dtype=float32)\n",
      "Tensor(\"flatten/Reshape:0\", shape=(?, 676), dtype=float32)\n",
      "Tensor(\"layer_fc_out/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "Total Parameters number = 22098\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\n",
    "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)\n",
    "\n",
    "# layer_conv1\n",
    "net = tf.layers.conv2d(inputs=x_image, name='layer_conv1', padding='same',\n",
    "                       filters=4, kernel_size=5, activation=tf.nn.relu)\n",
    "net = tf.layers.max_pooling2d(inputs=net, pool_size=4, strides=2)\n",
    "\n",
    "print(net)\n",
    "\n",
    "net = tf.layers.flatten(net)\n",
    "print(net)\n",
    "\n",
    "net = tf.layers.dense(inputs=net, name='layer_fc1',\n",
    "                      units=32, activation=tf.nn.relu)\n",
    "logits = tf.layers.dense(inputs=net, name='layer_fc_out',\n",
    "                      units=num_classes, activation=None)\n",
    "print(logits)\n",
    "\n",
    "y_pred = tf.nn.softmax(logits=logits)\n",
    "y_pred_cls = tf.argmax(y_pred, dimension=1)\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=logits)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "opt = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "optimizer = opt.minimize(loss)\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "trainable_var_list = tf.trainable_variables()\n",
    "\n",
    "par_num8 = prameter_num()\n",
    "\n",
    "print(\"Total Parameters number = %s\"  %par_num8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Testing Accuracy: 0.9616\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = 64\n",
    "n_batch = data.train.num_examples // train_batch_size\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for epoch in range(1):\n",
    "    for batch in range(n_batch):\n",
    "        batch_xs, batch_ys = data.train.next_batch(train_batch_size)\n",
    "        sess.run(optimizer, feed_dict={x:batch_xs, y_true:batch_ys})\n",
    "    loss8 = sess.run(loss, feed_dict={x:data.test.images,y_true:data.test.labels})\n",
    "    acc8 = sess.run(accuracy, feed_dict={x:data.test.images,y_true:data.test.labels})\n",
    "    lTrain8 = sess.run(loss, feed_dict={x:batch_xs, y_true:batch_ys})\n",
    "    aTrain8 = sess.run(accuracy, feed_dict={x:batch_xs, y_true:batch_ys})\n",
    "    print(\"Epoch \" + str(epoch) + \" Testing Accuracy: \" + str(acc8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"max_pooling2d/MaxPool:0\", shape=(?, 14, 14, 4), dtype=float32)\n",
      "Tensor(\"max_pooling2d_1/MaxPool:0\", shape=(?, 7, 7, 16), dtype=float32)\n",
      "Tensor(\"flatten/Reshape:0\", shape=(?, 784), dtype=float32)\n",
      "Tensor(\"layer_fc_out/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "Total Parameters number = 8026\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\n",
    "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)\n",
    "\n",
    "# layer_conv1\n",
    "net = tf.layers.conv2d(inputs=x_image, name='layer_conv1', padding='same',\n",
    "                       filters=4, kernel_size=3, activation=tf.nn.relu)\n",
    "net = tf.layers.max_pooling2d(inputs=net, pool_size=2, strides=2)\n",
    "\n",
    "print(net)\n",
    "\n",
    "# layer_conv2\n",
    "net = tf.layers.conv2d(inputs=net, name='layer_conv2', padding='same',\n",
    "                       filters=16, kernel_size=5, activation=tf.nn.relu)\n",
    "net = tf.layers.max_pooling2d(inputs=net, pool_size=2, strides=2)\n",
    "print(net)\n",
    "\n",
    "net = tf.layers.flatten(net)\n",
    "print(net)\n",
    "\n",
    "net = tf.layers.dense(inputs=net, name='layer_fc1',\n",
    "                      units=8, activation=tf.nn.relu)\n",
    "logits = tf.layers.dense(inputs=net, name='layer_fc_out',\n",
    "                      units=num_classes, activation=None)\n",
    "print(logits)\n",
    "\n",
    "y_pred = tf.nn.softmax(logits=logits)\n",
    "y_pred_cls = tf.argmax(y_pred, dimension=1)\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=logits)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "opt = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "optimizer = opt.minimize(loss)\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "trainable_var_list = tf.trainable_variables()\n",
    "\n",
    "par_num9 = prameter_num()\n",
    "\n",
    "print(\"Total Parameters number = %s\"  %par_num9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Testing Accuracy: 0.9738\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = 64\n",
    "n_batch = data.train.num_examples // train_batch_size\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for epoch in range(1):\n",
    "    for batch in range(n_batch):\n",
    "        batch_xs, batch_ys = data.train.next_batch(train_batch_size)\n",
    "        sess.run(optimizer, feed_dict={x:batch_xs, y_true:batch_ys})\n",
    "    loss9 = sess.run(loss, feed_dict={x:data.test.images,y_true:data.test.labels})\n",
    "    acc9 = sess.run(accuracy, feed_dict={x:data.test.images,y_true:data.test.labels})\n",
    "    lTrain9 = sess.run(loss, feed_dict={x:batch_xs, y_true:batch_ys})\n",
    "    aTrain9 = sess.run(accuracy, feed_dict={x:batch_xs, y_true:batch_ys})\n",
    "    print(\"Epoch \" + str(epoch) + \" Testing Accuracy: \" + str(acc9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"max_pooling2d_1/MaxPool:0\", shape=(?, 7, 7, 36), dtype=float32)\n",
      "Tensor(\"flatten/Reshape:0\", shape=(?, 1764), dtype=float32)\n",
      "Tensor(\"layer_fc_out/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "Total Parameters number = 242062\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\n",
    "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)\n",
    "\n",
    "# layer_conv1\n",
    "net = tf.layers.conv2d(inputs=x_image, name='layer_conv1', padding='same',\n",
    "                       filters=16, kernel_size=5, activation=tf.nn.relu)\n",
    "net = tf.layers.max_pooling2d(inputs=net, pool_size=2, strides=2)\n",
    "\n",
    "# layer_conv2\n",
    "net = tf.layers.conv2d(inputs=net, name='layer_conv2', padding='same',\n",
    "                       filters=36, kernel_size=5, activation=tf.nn.relu)\n",
    "net = tf.layers.max_pooling2d(inputs=net, pool_size=2, strides=2)\n",
    "print(net)\n",
    "\n",
    "net = tf.layers.flatten(net)\n",
    "print(net)\n",
    "\n",
    "net = tf.layers.dense(inputs=net, name='layer_fc1',\n",
    "                      units=128, activation=tf.nn.relu)\n",
    "logits = tf.layers.dense(inputs=net, name='layer_fc_out',\n",
    "                      units=num_classes, activation=None)\n",
    "print(logits)\n",
    "\n",
    "y_pred = tf.nn.softmax(logits=logits)\n",
    "y_pred_cls = tf.argmax(y_pred, dimension=1)\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_true, logits=logits)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "opt = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "optimizer = opt.minimize(loss)\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "trainable_var_list = tf.trainable_variables()\n",
    "\n",
    "par_num10 = prameter_num()\n",
    "\n",
    "print(\"Total Parameters number = %s\"  %par_num10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Testing Accuracy: 0.9664\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = 64\n",
    "n_batch = data.train.num_examples // train_batch_size\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for epoch in range(1):\n",
    "    for batch in range(n_batch):\n",
    "        batch_xs, batch_ys = data.train.next_batch(train_batch_size)\n",
    "        sess.run(optimizer, feed_dict={x:batch_xs, y_true:batch_ys})\n",
    "    loss10 = sess.run(loss, feed_dict={x:data.test.images,y_true:data.test.labels})\n",
    "    acc10 = sess.run(accuracy, feed_dict={x:data.test.images,y_true:data.test.labels})\n",
    "    lTrain10 = sess.run(loss, feed_dict={x:batch_xs, y_true:batch_ys})\n",
    "    aTrain10 = sess.run(accuracy, feed_dict={x:batch_xs, y_true:batch_ys})\n",
    "    print(\"Epoch \" + str(epoch) + \" Testing Accuracy: \" + str(acc10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x14c845264d68>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "para_num = [par_num1,par_num2,par_num3,par_num4,par_num5,par_num6,par_num7,par_num8,par_num9,par_num10]\n",
    "acc = [acc1,acc2,acc3,acc4,acc5,acc6,acc7,acc8,acc9,acc10]\n",
    "loss = [loss1,loss2,loss3,loss4,loss5,loss6,loss7,loss8,loss9,loss10]\n",
    "acc_train = [aTrain1,aTrain2,aTrain3,aTrain4,aTrain5,aTrain6,aTrain7,aTrain8,aTrain9,aTrain10]\n",
    "loss_train = [lTrain1,lTrain2,lTrain3,lTrain4,lTrain5,lTrain6,lTrain7,lTrain8,lTrain9,lTrain10]\n",
    "\n",
    "plt.scatter(para_num,acc, c='r')\n",
    "plt.scatter(para_num,acc_train, c='b')\n",
    "plt.show\n",
    "plt.title('Accuracy with different parameter numbers')\n",
    "plt.xlabel('parameter number')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(('test accuracy','train accuracy'))\n",
    "\n",
    "plt.pause(0.1)\n",
    "plt.scatter(para_num,loss, c='g')\n",
    "plt.scatter(para_num,loss_train,c='y')\n",
    "plt.show\n",
    "plt.title('Loss with different parameter numbers')\n",
    "plt.xlabel('parameter number')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(('test loss','train loss'))\n",
    "\n",
    "# plt.pause(0.1)\n",
    "# plt.scatter(par_num8,acc8)\n",
    "# plt.scatter(par_num8,aTrain8)\n",
    "# plt.legend(('test accuracy','train accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "8810"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
